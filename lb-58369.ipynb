{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from numba import jit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Manager\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Loading train data\n",
      "(21838516, 6)\n",
      "Feature engineering on train\n",
      "Loading test data\n",
      "(7279505, 5)\n",
      "Feature engineering on test\n",
      "('Data prepared in:', datetime.timedelta(0, 76, 728079))\n",
      "('Row', 0, 'completed in:', datetime.timedelta(0, 0, 795217))\n",
      "('Row', 1, 'completed in:', datetime.timedelta(0, 0, 455884))\n",
      "('Row', 2, 'completed in:', datetime.timedelta(0, 0, 493445))\n",
      "('Row', 3, 'completed in:', datetime.timedelta(0, 0, 576533))\n",
      "('Row', 4, 'completed in:', datetime.timedelta(0, 0, 652017))\n",
      "('Row', 5, 'completed in:', datetime.timedelta(0, 629, 110204))\n",
      "('Row', 6, 'completed in:', datetime.timedelta(0, 2, 743233))\n",
      "('Row', 7, 'completed in:', datetime.timedelta(0, 0, 501800))\n",
      "('Row', 8, 'completed in:', datetime.timedelta(0, 0, 509507))\n",
      "('Row', 9, 'completed in:', datetime.timedelta(0, 0, 671198))\n",
      "('Row', 10, 'completed in:', datetime.timedelta(0, 0, 613656))\n",
      "('Row', 11, 'completed in:', datetime.timedelta(0, 640, 275330))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ef62346d1465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m preds = process_grid(train, test, x_cuts, y_cuts, t_cuts,\n\u001b[1;32m    348\u001b[0m                      \u001b[0mx_border_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_border_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_aug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                      fw, th, n_neighbors)\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predictions made in:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-ef62346d1465>\u001b[0m in \u001b[0;36mprocess_grid\u001b[0;34m(train, test, x_cuts, y_cuts, t_cuts, x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Row'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'completed in:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/numpy-1.11.1-py2.7-macosx-10.10-intel.egg/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# Found at: https://www.kaggle.com/rshekhar2/facebook-v-predicting-check-ins/xgboost-cv-example-with-small-bug\n",
    "def mapkprecision(truthvalues, predictions):\n",
    "    '''\n",
    "    This is a faster implementation of MAP@k valid for numpy arrays.\n",
    "    It is only valid when there is one single truth value. \n",
    "\n",
    "    m ~ number of observations\n",
    "    k ~ MAP at k -- in this case k should equal 3\n",
    "\n",
    "    truthvalues.shape = (m,) \n",
    "    predictions.shape = (m, k)\n",
    "    '''\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return np.mean(np.sum(z, axis=1))\n",
    "\n",
    "def load_data(data_name):\n",
    "    types = {'row_id': np.dtype(np.int32),\n",
    "         'x': np.dtype(float),\n",
    "         'y' : np.dtype(float),\n",
    "         'accuracy': np.dtype(np.int16),\n",
    "         'place_id': np.int64,\n",
    "         'time': np.dtype(np.int32)}\n",
    "    df = pd.read_csv(data_name, dtype=types, na_filter=False)\n",
    "    return df\n",
    "    \n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2.3\n",
    "    \n",
    "# Faster than argsort at getting top three predictions\n",
    "#@jit(nopython=True)\n",
    "def top_three_preds(preds):\n",
    "    place_count = preds.shape[0]\n",
    "    preds_count = preds.shape[1]\n",
    "    pred_labels = np.zeros((place_count, 3), dtype=np.int32)\n",
    "    for i in range(place_count):\n",
    "        first_place_score = 0\n",
    "        second_place_score = 0\n",
    "        third_place_score = 0\n",
    "        for j in range(preds_count):\n",
    "            this_pred = preds[i,j]\n",
    "            if (this_pred > 0) and (this_pred > third_place_score):\n",
    "                if this_pred > second_place_score:\n",
    "                    pred_labels[i, 2] = pred_labels[i, 1]\n",
    "                    third_place_score = second_place_score\n",
    "                    if this_pred > first_place_score:\n",
    "                        pred_labels[i, 1] = pred_labels[i, 0]\n",
    "                        second_place_score = first_place_score\n",
    "                        first_place_score = this_pred\n",
    "                        pred_labels[i, 0] = j\n",
    "                    else:\n",
    "                        second_place_score = this_pred\n",
    "                        pred_labels[i, 1] = j\n",
    "                else:\n",
    "                    third_place_score = this_pred\n",
    "                    pred_labels[i, 2] = j\n",
    "    return pred_labels\n",
    "    \n",
    "# Precompute the trig values\n",
    "def time_trig(max_time):\n",
    "    time_array = np.linspace(0, 2*np.pi, max_time)\n",
    "    sin_values = np.sin(time_array)\n",
    "    cos_values = np.cos(time_array)\n",
    "    return (sin_values, cos_values)\n",
    "    \n",
    "# Generate a dictionary of the time limits so it doesn't have to be \n",
    "# recalculated each loop\n",
    "def create_time_dict(t_cuts, time_mod, time_weight, time_aug):\n",
    "    \n",
    "    t_slice = 24 / t_cuts\n",
    "    time_dict = dict()\n",
    "    trig_array = time_trig(time_mod)\n",
    "    for t in range(t_cuts):\n",
    "        \n",
    "        t_min = int(t * t_slice * 12)\n",
    "        t_max = int((t + 1) * t_slice * 12 - 1)\n",
    "        sin_t_start = trig_array[0][t_min] * time_weight\n",
    "        sin_t_stop = trig_array[0][t_max] * time_weight\n",
    "        cos_t_start = trig_array[1][t_min] * time_weight\n",
    "        cos_t_stop = trig_array[1][t_max] * time_weight\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop))\n",
    "        time_dict[t] = [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "\n",
    "        t_min = int((t * t_slice - time_aug) * 12)%time_mod\n",
    "        t_max = int(((t + 1) * t_slice + time_aug)* 12 - 1)%time_mod\n",
    "        sin_t_start = trig_array[0][t_min] * time_weight\n",
    "        sin_t_stop = trig_array[0][t_max] * time_weight\n",
    "        cos_t_start = trig_array[1][t_min] * time_weight\n",
    "        cos_t_stop = trig_array[1][t_max] * time_weight\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop, sin_t_min))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop, sin_t_max))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop, cos_t_min))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop, cos_t_max))\n",
    "        time_dict[t] += [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "        \n",
    "    return time_dict\n",
    "\n",
    "#@jit\n",
    "def apply_mask(data, feature, mask_min, mask_max):\n",
    "    mask = (data[:, feature] >= mask_min)\n",
    "    mask = mask & (data[:, feature] < mask_max)      \n",
    "    return data[mask]  \n",
    "\n",
    "def get_preds(cell_train, cell_test, n_neighbors):\n",
    "    # Preparing data\n",
    "    y = cell_train[:, -1].flatten().astype(np.int64)\n",
    "    X = cell_train[:, :-1]\n",
    "    \n",
    "    #Applying the classifier\n",
    "    cte = 5.8\n",
    "    n_neighbors = int((y.size ** 0.5) / cte)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "                            weights=calculate_distance, p=1,\n",
    "                            n_jobs=2, leaf_size=15)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(cell_test)\n",
    "    return y_pred, clf.classes_\n",
    "\n",
    "def process_one_cell(cell_train, cell_test, fw, th, n_neighbors):\n",
    "    # Remove infrequent places\n",
    "    places, idx, counts = np.unique(cell_train[:, -1], return_inverse=True, return_counts=True)\n",
    "    count_per_row = counts[idx]\n",
    "    cell_train = cell_train[count_per_row >= th]\n",
    "\n",
    "    # Store row_ids for test\n",
    "    row_ids = cell_test[:, -1].flatten().astype(np.int32)\n",
    "    cell_test = cell_test[:, :-1]\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred, classes = get_preds(cell_train, cell_test, n_neighbors)\n",
    "    #save predictions to disc here\n",
    "    preds_all = dict(zip(classes, zip(*y_pred)))\n",
    "    preds_all = pd.DataFrame.from_dict(preds_all)\n",
    "    preds_all['row_id'] = row_ids;\n",
    "    preds_all = preds_all.set_index('row_id')\n",
    "\n",
    "    #preds_all.to_csv(\"./raw/cv/knn-lb-58369/\" + str(x_min) + \"_\" + str(y_min) + \".csv\", index = False);\n",
    "    \n",
    "    # Get top three predictions\n",
    "    #y_pred_labels = top_three_preds(y_pred)\n",
    "    #pred_labels = classes[y_pred_labels]\n",
    "    #cell_pred = np.column_stack((row_ids, pred_labels)).astype(np.int64) \n",
    "    \n",
    "    return preds_all\n",
    "\n",
    "def process_column(time_dict, x_index, y_slice, y_cuts, col_train, col_test, fw, th, n_neighbors):\n",
    "    for j in range(y_cuts):\n",
    "        y_min = y_slice * j\n",
    "        y_index = y_min/fw[5]\n",
    "        y_max = y_slice * (j+1)\n",
    "        y_max += int((j+1) == y_cuts) # expand edge at end\n",
    "\n",
    "        row_test = apply_mask(col_test, 1, y_min, y_max)\n",
    "        y_min -= y_border_aug\n",
    "        y_max += y_border_aug\n",
    "        row_train = apply_mask(col_train, 1, y_min, y_max)\n",
    "\n",
    "        preds_list_all = pd.DataFrame();\n",
    "        for t in range(t_cuts):\n",
    "            #print(df_row_test.shape, df_row_train.shape)\n",
    "            t_lim = time_dict[t]\n",
    "            mask = (row_test[:, 2] >= t_lim[0])\n",
    "            mask = mask & (row_test[:, 2] <= t_lim[1])\n",
    "            mask = mask & (row_test[:, 3] >= t_lim[2])\n",
    "            mask = mask & (row_test[:, 3] <= t_lim[3])\n",
    "            cell_test = row_test[mask]\n",
    "            mask = (row_train[:, 2] >= t_lim[4])\n",
    "            mask = mask & (row_train[:, 2] <= t_lim[5])\n",
    "            mask = mask & (row_train[:, 3] >= t_lim[6])\n",
    "            mask = mask & (row_train[:, 3] <= t_lim[7])\n",
    "            cell_train = row_train[mask]\n",
    "            cell_pred = process_one_cell(cell_train, cell_test, \n",
    "                                         fw, th, n_neighbors)\n",
    "            #print cell_pred.shape\n",
    "            preds_list_all = preds_list_all.add(cell_pred, fill_value=0).fillna(value=0);\n",
    "\n",
    "        preds_list_all.sort_index().to_csv(\"./raw/cv/knn-lb-58369/\" + str(x_index) + \"_\" \n",
    "                                           + str(y_index) + \".csv\", index = True);\n",
    "\n",
    "def process_grid(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                 x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors):\n",
    "    preds_list = []\n",
    "    x_slice = train[:, 0].max() / x_cuts\n",
    "    y_slice = train[:, 1].max() / y_cuts\n",
    "    time_mod = 288\n",
    "    time_weight = fw[2]\n",
    "    time_dict = create_time_dict(t_cuts, time_mod, time_weight, time_aug)\n",
    "\n",
    "    jobs = []\n",
    "    for i in range(x_cuts):\n",
    "        row_start_time = time.time()\n",
    "        x_min = x_slice * i\n",
    "        x_index = x_min/fw[4]\n",
    "        x_max = x_slice * (i+1)\n",
    "        x_max += int((i+1) == x_cuts) # expand edge at end\n",
    "\n",
    "        col_test = apply_mask(test, 0, x_min, x_max)\n",
    "        x_min -= x_border_aug\n",
    "        x_max += x_border_aug\n",
    "        col_train = apply_mask(train, 0, x_min, x_max)\n",
    "    \n",
    "        p = multiprocessing.Process(target=process_column, args=(time_dict, x_index, y_slice, y_cuts, col_train,\n",
    "                                                                 col_test, fw, th, n_neighbors))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        if len(jobs) == 6:\n",
    "            for proc in jobs:\n",
    "                proc.join();\n",
    "            jobs = [];\n",
    "            \n",
    "        elapsed = (time.time() - row_start_time)\n",
    "        print('Row', i, 'completed in:', timedelta(seconds=elapsed))\n",
    "    #preds = np.vstack(preds_list)\n",
    "    #return preds\n",
    "\n",
    "# Thank you Alex!\n",
    "# From: https://www.kaggle.com/drarfc/facebook-v-predicting-check-ins/fastest-way-to-write-the-csv\n",
    "def generate_submission(preds):    \n",
    "    print('Writing submission file')\n",
    "    with open('KNN_submission.csv', \"w\") as out:\n",
    "        out.write(\"row_id,place_id\\n\")\n",
    "        rows = ['']*8607230\n",
    "        n=0\n",
    "        for num in range(8607230):\n",
    "            rows[n]='%d,%d %d %d\\n' % (preds[num,0],preds[num,1],preds[num,2],preds[num,3])\n",
    "            n=n+1\n",
    "        out.writelines(rows)\n",
    "\n",
    "def validation_split(df, val_start_day):\n",
    "    day = df['time']//1440\n",
    "    df_val = df.loc[(day>=val_start_day)].copy()\n",
    "    df = df.loc[(day<val_start_day)].copy()\n",
    "    return df, df_val\n",
    "    \n",
    "def remove_infrequent_places_df(df, th=5):\n",
    "    place_counts = df.place_id.value_counts()\n",
    "    mask = (place_counts[df.place_id.values] >= th).values\n",
    "    df = df[mask]\n",
    "    return df\n",
    "\n",
    "def prepare_data(datapath, val_start_day, train_columns, test_columns, \n",
    "                 fw, th, off):\n",
    "    val_label = None\n",
    "    print('Loading train data')\n",
    "    train_data = load_data(datapath + 'train.csv')\n",
    "    train_data = train_data.sort_values(by='time', axis=0, ascending=True)\n",
    "    df_train = train_data[train_data.shape[0]//4:]\n",
    "    print df_train.shape\n",
    "    if val_start_day > 0:\n",
    "        # Create validation data\n",
    "        df_train, df_test = validation_split(df_train, val_start_day)\n",
    "        val_label = df_test['place_id'] \n",
    "        df_test.drop(['place_id'], axis=1, inplace=True)    \n",
    "    print('Feature engineering on train')\n",
    "    df_train.drop(['row_id'], axis=1, inplace=True)\n",
    "    df_train = remove_infrequent_places_df(df_train, th)\n",
    "    gc.collect()\n",
    "    df_train = feature_engineering(df_train, off)\n",
    "    df_train = apply_weights(df_train, fw)\n",
    "    # reorder the columns so the place id is at the end\n",
    "    train = df_train[train_columns].values\n",
    "    del df_train\n",
    "    gc.collect()\n",
    "    if val_start_day == 0:\n",
    "        print('Loading test data')\n",
    "        #df_test = load_data(datapath + 'test.csv') \n",
    "        df_test = train_data[:train_data.shape[0]//4]\n",
    "        df_test.drop(['place_id'], axis=1, inplace=True)\n",
    "        print df_test.shape\n",
    "    print('Feature engineering on test')\n",
    "    df_test = feature_engineering(df_test, off)\n",
    "    df_test = apply_weights(df_test, fw)\n",
    "    test = df_test[test_columns].values\n",
    "    del df_test\n",
    "    gc.collect()\n",
    "    return train, test, val_label\n",
    "        \n",
    "def apply_weights(df, fw):\n",
    "    df['accuracy'] *= fw[0]\n",
    "    df['day_of_year_sin'] *= fw[1]\n",
    "    df['day_of_year_cos'] *= fw[1]\n",
    "    df['minute_sin'] *= fw[2]\n",
    "    df['minute_cos'] *= fw[2]\n",
    "    df['weekday_sin'] *= fw[3]\n",
    "    df['weekday_cos'] *= fw[3]\n",
    "    df.x *= fw[4]\n",
    "    df.y *= fw[5]\n",
    "    df['year'] *= fw[6]\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df, off):\n",
    "    minute =((df[\"time\"]+off[0])//5)%288\n",
    "    trig_arrays = time_trig(288)\n",
    "    df['minute_sin'] = trig_arrays[0][minute.tolist()]\n",
    "    df['minute_cos'] = trig_arrays[1][minute.tolist()]\n",
    "    del minute\n",
    "    day = ((df['time']+off[1])//1440)%365\n",
    "    trig_arrays = time_trig(365)\n",
    "    df['day_of_year_sin'] = trig_arrays[0][day.tolist()]\n",
    "    df['day_of_year_cos'] = trig_arrays[1][day.tolist()]\n",
    "    del day\n",
    "    weekday = ((df['time']+off[2])//1440)%7\n",
    "    trig_arrays = time_trig(7)\n",
    "    df['weekday_sin'] = trig_arrays[0][weekday.tolist()]\n",
    "    df['weekday_cos'] = trig_arrays[1][weekday.tolist()]\n",
    "    del weekday\n",
    "    df['year'] = (df['time']//525600).astype(float)\n",
    "    df.drop(['time'], axis=1, inplace=True)\n",
    "    df['accuracy'] = np.log10(df['accuracy']).astype(float)\n",
    "    return df\n",
    "    \n",
    "print('Starting...')\n",
    "start_time = time.time()\n",
    "# Global variables\n",
    "datapath = './input/'\n",
    "# Change val_start_day to zero to generate predictions\n",
    "val_start_day = 0 # Day at which to cut validation\n",
    "th = 5 # Threshold at which to cut places from train\n",
    "fw = [127., 33.6, 64.4, 26., 2300, 5625, 55.6]\n",
    "off = [444, 931, 421]\n",
    "\n",
    "# Defining the size of the grid\n",
    "x_cuts = 12 # number of cuts along x \n",
    "y_cuts = 25 # number of cuts along y\n",
    "#TODO: More general solution for t_cuts. For now must be 4.\n",
    "t_cuts = 4 # number of cuts along time. \n",
    "x_border_aug = 0.0052 * fw[4] # expansion of x border on train \n",
    "y_border_aug = 0.0042 * fw[5] # expansion of y border on train\n",
    "time_aug = 2.5\n",
    "n_neighbors = 0\n",
    "columns = ['x', 'y', 'minute_sin', 'minute_cos', 'accuracy',\n",
    "           'day_of_year_sin', 'day_of_year_cos', \n",
    "           'weekday_sin', 'weekday_cos', 'year']\n",
    "train_columns = columns + ['place_id']\n",
    "test_columns  = columns + ['row_id']\n",
    "\n",
    "train, test, val_label = prepare_data(datapath, val_start_day,\n",
    "                                      train_columns, test_columns, fw, th, off)\n",
    "\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Data prepared in:', timedelta(seconds=elapsed))\n",
    "    \n",
    "preds = process_grid(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                     x_border_aug, y_border_aug, time_aug, \n",
    "                     fw, th, n_neighbors)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Predictions made in:', timedelta(seconds=elapsed))\n",
    "\n",
    "if val_start_day > 0:\n",
    "    preds = preds[preds[:, 0] > 0] # only use rows predicted\n",
    "    labels = val_label.loc[preds[:, 0]].values\n",
    "    score = mapkprecision(labels, preds[:, 1:])\n",
    "    print('Final score:', score)\n",
    "else:\n",
    "    #print('Pred shape:', preds.shape)\n",
    "    #generate_submission(preds)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Task completed in:', timedelta(seconds=elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Loading train data\n",
      "(21838516, 6)\n",
      "Feature engineering on train\n",
      "Loading test data\n",
      "(7279505, 5)\n",
      "Feature engineering on test\n",
      "('Data prepared in:', datetime.timedelta(0, 79, 288940))\n",
      "('Row', 0, 'completed in:', datetime.timedelta(0, 0, 528621))\n",
      "('Row', 1, 'completed in:', datetime.timedelta(0, 0, 291267))\n",
      "('Row', 2, 'completed in:', datetime.timedelta(0, 0, 353188))\n",
      "('Row', 3, 'completed in:', datetime.timedelta(0, 0, 462359))\n",
      "('Row', 4, 'completed in:', datetime.timedelta(0, 0, 828611))\n",
      "('Row', 5, 'completed in:', datetime.timedelta(0, 0, 980352))\n",
      "('Row', 6, 'completed in:', datetime.timedelta(0, 0, 870705))\n",
      "('Row', 7, 'completed in:', datetime.timedelta(0, 1, 368163))\n",
      "('Row', 8, 'completed in:', datetime.timedelta(0, 1, 546273))\n",
      "('Row', 9, 'completed in:', datetime.timedelta(0, 1290, 387615))\n",
      "('Row', 10, 'completed in:', datetime.timedelta(0, 2, 225389))\n",
      "('Row', 11, 'completed in:', datetime.timedelta(0, 0, 315994))\n",
      "('Row', 12, 'completed in:', datetime.timedelta(0, 0, 606707))\n",
      "('Row', 13, 'completed in:', datetime.timedelta(0, 0, 449473))\n",
      "('Row', 14, 'completed in:', datetime.timedelta(0, 0, 966187))\n",
      "('Row', 15, 'completed in:', datetime.timedelta(0, 1, 27471))\n",
      "('Row', 16, 'completed in:', datetime.timedelta(0, 1, 145884))\n",
      "('Row', 17, 'completed in:', datetime.timedelta(0, 1, 11657))\n",
      "('Row', 18, 'completed in:', datetime.timedelta(0, 1, 399807))\n",
      "('Row', 19, 'completed in:', datetime.timedelta(0, 1352, 683678))\n",
      "('Row', 20, 'completed in:', datetime.timedelta(0, 2, 391452))\n",
      "('Row', 21, 'completed in:', datetime.timedelta(0, 0, 347594))\n",
      "('Row', 22, 'completed in:', datetime.timedelta(0, 0, 453098))\n",
      "('Row', 23, 'completed in:', datetime.timedelta(0, 0, 491550))\n",
      "('Row', 24, 'completed in:', datetime.timedelta(0, 0, 477884))\n",
      "('Row', 25, 'completed in:', datetime.timedelta(0, 0, 834517))\n",
      "('Row', 26, 'completed in:', datetime.timedelta(0, 1, 248035))\n",
      "('Row', 27, 'completed in:', datetime.timedelta(0, 1, 256384))\n",
      "('Row', 28, 'completed in:', datetime.timedelta(0, 1, 465883))\n",
      "('Row', 29, 'completed in:', datetime.timedelta(0, 1396, 669794))\n",
      "('Row', 30, 'completed in:', datetime.timedelta(0, 1, 876467))\n",
      "('Row', 31, 'completed in:', datetime.timedelta(0, 0, 343609))\n",
      "('Row', 32, 'completed in:', datetime.timedelta(0, 0, 624902))\n",
      "('Row', 33, 'completed in:', datetime.timedelta(0, 0, 485347))\n",
      "('Row', 34, 'completed in:', datetime.timedelta(0, 0, 901676))\n",
      "('Row', 35, 'completed in:', datetime.timedelta(0, 1, 59020))\n",
      "('Row', 36, 'completed in:', datetime.timedelta(0, 1, 257751))\n",
      "('Row', 37, 'completed in:', datetime.timedelta(0, 1, 535810))\n",
      "('Row', 38, 'completed in:', datetime.timedelta(0, 1, 533174))\n",
      "('Row', 39, 'completed in:', datetime.timedelta(0, 1437, 60076))\n",
      "('Row', 40, 'completed in:', datetime.timedelta(0, 2, 9181))\n",
      "('Row', 41, 'completed in:', datetime.timedelta(0, 0, 334925))\n",
      "('Row', 42, 'completed in:', datetime.timedelta(0, 0, 463197))\n",
      "('Row', 43, 'completed in:', datetime.timedelta(0, 0, 626763))\n",
      "('Row', 44, 'completed in:', datetime.timedelta(0, 0, 908073))\n",
      "('Row', 45, 'completed in:', datetime.timedelta(0, 0, 988219))\n",
      "('Row', 46, 'completed in:', datetime.timedelta(0, 1, 199961))\n",
      "('Row', 47, 'completed in:', datetime.timedelta(0, 1, 597406))\n",
      "('Row', 48, 'completed in:', datetime.timedelta(0, 1, 594202))\n",
      "('Row', 49, 'completed in:', datetime.timedelta(0, 1317, 455363))\n",
      "('Predictions made in:', datetime.timedelta(0, 6918, 364792))\n",
      "('Task completed in:', datetime.timedelta(0, 6918, 365792))\n"
     ]
    }
   ],
   "source": [
    "def get_preds(cell_train, cell_test, n_neighbors):\n",
    "    # Preparing data\n",
    "    y = cell_train[:, -1].flatten().astype(np.int64)\n",
    "    X = cell_train[:, :-1]\n",
    "    \n",
    "    #Applying the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=65, max_depth=None, n_jobs=-1,\n",
    "                         min_samples_split=4, random_state=0, criterion='gini')\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(cell_test)\n",
    "    clf2 = RandomForestClassifier(n_estimators=65, max_depth=None, n_jobs=-1,\n",
    "                         min_samples_split=4, random_state=0, criterion='entropy')\n",
    "    clf2.fit(X, y)\n",
    "    y_pred2 = clf2.predict_proba(cell_test)\n",
    "    \n",
    "    y_pred = (y_pred + y_pred2)/2;\n",
    "        \n",
    "    return y_pred, clf.classes_ \n",
    "\n",
    "def process_one_cell(cell_train, cell_test, fw, th, n_neighbors):\n",
    "    # Remove infrequent places\n",
    "    places, idx, counts = np.unique(cell_train[:, -1], return_inverse=True, return_counts=True)\n",
    "    count_per_row = counts[idx]\n",
    "    cell_train = cell_train[count_per_row >= th]\n",
    "\n",
    "    # Store row_ids for test\n",
    "    row_ids = cell_test[:, -1].flatten().astype(np.int32)\n",
    "    cell_test = cell_test[:, :-1]\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred, classes = get_preds(cell_train, cell_test, n_neighbors)\n",
    "    preds_all = dict(zip(classes, zip(*y_pred)))\n",
    "    preds_all = pd.DataFrame.from_dict(preds_all)\n",
    "    preds_all['row_id'] = row_ids;\n",
    "    preds_all = preds_all.set_index('row_id')\n",
    "    \n",
    "    return preds_all\n",
    "\n",
    "\n",
    "def process_column(time_dict, x_index, y_slice, y_cuts, col_train, col_test, fw, th, n_neighbors, output):\n",
    "    for j in range(y_cuts):\n",
    "        y_min = y_slice * j\n",
    "        y_index = y_min/fw[5]\n",
    "        y_max = y_slice * (j+1)\n",
    "        y_max += int((j+1) == y_cuts) # expand edge at end\n",
    "\n",
    "        row_test = apply_mask(col_test, 1, y_min, y_max)\n",
    "        y_min -= y_border_aug\n",
    "        y_max += y_border_aug\n",
    "        row_train = apply_mask(col_train, 1, y_min, y_max)\n",
    "\n",
    "        preds_list_all = pd.DataFrame();\n",
    "        for t in range(t_cuts):\n",
    "            #print(df_row_test.shape, df_row_train.shape)\n",
    "            t_lim = time_dict[t]\n",
    "            mask = (row_test[:, 2] >= t_lim[0])\n",
    "            mask = mask & (row_test[:, 2] <= t_lim[1])\n",
    "            mask = mask & (row_test[:, 3] >= t_lim[2])\n",
    "            mask = mask & (row_test[:, 3] <= t_lim[3])\n",
    "            cell_test = row_test[mask]\n",
    "            mask = (row_train[:, 2] >= t_lim[4])\n",
    "            mask = mask & (row_train[:, 2] <= t_lim[5])\n",
    "            mask = mask & (row_train[:, 3] >= t_lim[6])\n",
    "            mask = mask & (row_train[:, 3] <= t_lim[7])\n",
    "            cell_train = row_train[mask]\n",
    "            cell_pred = process_one_cell(cell_train, cell_test, \n",
    "                                         fw, th, n_neighbors)\n",
    "            #print cell_pred.shape\n",
    "            preds_list_all = preds_list_all.add(cell_pred, fill_value=0).fillna(value=0);\n",
    "\n",
    "        #preds_list_all.sort_index().to_csv(\"./raw/cv/rf-lb-58369/\" + str(x_index) + \"_\" \n",
    "        #                                   + str(y_index) + \".csv\", index = True);\n",
    "        preds_list_all.sort_index().to_csv(output + str(x_index) + \"_\" \n",
    "                                           + str(y_index) + \".csv\", index = True);\n",
    "\n",
    "\n",
    "    \n",
    "def process_grid(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                 x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors, output):\n",
    "    preds_list = []\n",
    "    x_slice = train[:, 0].max() / x_cuts\n",
    "    y_slice = train[:, 1].max() / y_cuts\n",
    "    time_mod = 288\n",
    "    time_weight = fw[2]\n",
    "    time_dict = create_time_dict(t_cuts, time_mod, time_weight, time_aug)\n",
    "\n",
    "    jobs = []\n",
    "    for i in range(x_cuts):\n",
    "        row_start_time = time.time()\n",
    "        x_min = x_slice * i\n",
    "        x_index = x_min/fw[4]\n",
    "        x_max = x_slice * (i+1)\n",
    "        x_max += int((i+1) == x_cuts) # expand edge at end\n",
    "\n",
    "        col_test = apply_mask(test, 0, x_min, x_max)\n",
    "        x_min -= x_border_aug\n",
    "        x_max += x_border_aug\n",
    "        col_train = apply_mask(train, 0, x_min, x_max)\n",
    "\n",
    "        p = multiprocessing.Process(target=process_column, args=(time_dict, x_index, y_slice, y_cuts, col_train,\n",
    "                                                                 col_test, fw, th, n_neighbors, output))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        if len(jobs) == 10:\n",
    "            for proc in jobs:\n",
    "                proc.join();\n",
    "            jobs = [];\n",
    "            \n",
    "        elapsed = (time.time() - row_start_time)\n",
    "        print('Row', i, 'completed in:', timedelta(seconds=elapsed))\n",
    "    #preds = np.vstack(preds_list)\n",
    "    #return preds\n",
    "    \n",
    "    \n",
    "def prepare_data(datapath, val_start_day, train_columns, test_columns, \n",
    "                 fw, th, off):\n",
    "    val_label = None\n",
    "    print('Loading train data')\n",
    "    df_train = load_data(datapath + 'train.csv')\n",
    "    #train_data = train_data.sort_values(by='time', axis=0, ascending=True)\n",
    "    #df_train = train_data[train_data.shape[0]//4:]\n",
    "    print df_train.shape\n",
    "    if val_start_day > 0:\n",
    "        # Create validation data\n",
    "        df_train, df_test = validation_split(df_train, val_start_day)\n",
    "        val_label = df_test['place_id'] \n",
    "        df_test.drop(['place_id'], axis=1, inplace=True)    \n",
    "    print('Feature engineering on train')\n",
    "    df_train.drop(['row_id'], axis=1, inplace=True)\n",
    "    df_train = remove_infrequent_places_df(df_train, th)\n",
    "    gc.collect()\n",
    "    df_train = feature_engineering(df_train, off)\n",
    "    df_train = apply_weights(df_train, fw)\n",
    "    # reorder the columns so the place id is at the end\n",
    "    train = df_train[train_columns].values\n",
    "    del df_train\n",
    "    gc.collect()\n",
    "    if val_start_day == 0:\n",
    "        print('Loading test data')\n",
    "        df_test = load_data(datapath + 'test.csv') \n",
    "        #df_test = train_data[:train_data.shape[0]//4]\n",
    "        #df_test.drop(['place_id'], axis=1, inplace=True)\n",
    "        print df_test.shape\n",
    "    print('Feature engineering on test')\n",
    "    df_test = feature_engineering(df_test, off)\n",
    "    df_test = apply_weights(df_test, fw)\n",
    "    test = df_test[test_columns].values\n",
    "    del df_test\n",
    "    gc.collect()\n",
    "    return train, test, val_label\n",
    "    \n",
    "    \n",
    "print('Starting...')\n",
    "start_time = time.time()\n",
    "# Global variables\n",
    "datapath = './input/'\n",
    "# Change val_start_day to zero to generate predictions\n",
    "val_start_day = 0 # Day at which to cut validation\n",
    "###########################################################################################\n",
    "th = 3 # Threshold at which to cut places from train\n",
    "###########################################################################################\n",
    "fw = [127., 33.6, 64.4, 26., 2300, 5625, 55.6]\n",
    "off = [444, 931, 421]\n",
    "\n",
    "# Defining the size of the grid\n",
    "x_cuts = 50 # number of cuts along x \n",
    "y_cuts = 125 # number of cuts along y\n",
    "#TODO: More general solution for t_cuts. For now must be 4.\n",
    "t_cuts = 4 # number of cuts along time. \n",
    "x_border_aug = 0.0052 * fw[4] # expansion of x border on train \n",
    "y_border_aug = 0.0042 * fw[5] # expansion of y border on train\n",
    "time_aug = 2.5\n",
    "\n",
    "columns = ['x', 'y', 'minute_sin', 'minute_cos', 'accuracy',\n",
    "           'day_of_year_sin', 'day_of_year_cos', \n",
    "           'weekday_sin', 'weekday_cos', 'year']\n",
    "train_columns = columns + ['place_id']\n",
    "test_columns  = columns + ['row_id']\n",
    "\n",
    "train, test, val_label = prepare_data(datapath, val_start_day,\n",
    "                                      train_columns, test_columns, fw, 3, off)\n",
    "\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Data prepared in:', timedelta(seconds=elapsed))\n",
    "    \n",
    "preds = process_grid(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                     x_border_aug, y_border_aug, time_aug, \n",
    "                     fw, th, n_neighbors, './raw/cv/rf-lb-58369-th3/')\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Predictions made in:', timedelta(seconds=elapsed))\n",
    "\n",
    "if val_start_day > 0:\n",
    "    preds = preds[preds[:, 0] > 0] # only use rows predicted\n",
    "    labels = val_label.loc[preds[:, 0]].values\n",
    "    score = mapkprecision(labels, preds[:, 1:])\n",
    "    print('Final score:', score)\n",
    "else:\n",
    "    #print('Pred shape:', preds.shape)\n",
    "    #generate_submission(preds)\n",
    "    pass\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Task completed in:', timedelta(seconds=elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
