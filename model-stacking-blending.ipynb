{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Manager\n",
    "\n",
    "import math\n",
    "import xgboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ml_metrics import mapk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29118021, 10)\n",
      "(8607230, 9)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Feature engineering\n",
    "    \"\"\"\n",
    "    minute = df.time % 60\n",
    "    df['hour'] = df['time'] // 60\n",
    "    #df.drop(['time'], axis=1, inplace=True)\n",
    "    df['weekday'] = df['hour'] // 24\n",
    "    df['month'] = df['weekday'] // 30\n",
    "    df['year'] = (df['weekday'] // 365 + 1) * 10.0\n",
    "    df['hour'] = ((df['hour'] % 24 + 1) + minute / 60.0) * 4.0\n",
    "    df['weekday'] = (df['weekday'] % 7 + 1) * 3.0\n",
    "    df['month'] = (df['month'] % 12 + 1) * 2.0\n",
    "    df['accuracy'] = np.log10(df['accuracy']) * 10.0\n",
    "\n",
    "    return df\n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "train = prepare_data(train)\n",
    "test = prepare_data(test)\n",
    "\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_weights(df, fw):\n",
    "    df['accuracy'] *= fw[0]\n",
    "    df['day_of_year_sin'] *= fw[1]\n",
    "    df['day_of_year_cos'] *= fw[1]\n",
    "    df['minute_sin'] *= fw[2]\n",
    "    df['minute_cos'] *= fw[2]\n",
    "    df['weekday_sin'] *= fw[3]\n",
    "    df['weekday_cos'] *= fw[3]\n",
    "    #df.x *= fw[4]\n",
    "    #df.y *= fw[5]\n",
    "    df['year'] *= fw[6]\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    minute = 2*np.pi*((df[\"time\"]//5)%288)/288\n",
    "    df['minute_sin'] = (np.sin(minute)+1).round(4)\n",
    "    df['minute_cos'] = (np.cos(minute)+1).round(4)\n",
    "    del minute\n",
    "    day = 2*np.pi*((df['time']//1440)%365)/365\n",
    "    df['day_of_year_sin'] = (np.sin(day)+1).round(4)\n",
    "    df['day_of_year_cos'] = (np.cos(day)+1).round(4)\n",
    "    del day\n",
    "    weekday = 2*np.pi*((df['time']//1440)%7)/7\n",
    "    df['weekday_sin'] = (np.sin(weekday)+1).round(4)\n",
    "    df['weekday_cos'] = (np.cos(weekday)+1).round(4)\n",
    "    del weekday\n",
    "    df['year'] = (df['time']//525600).astype(float)\n",
    "    #df.drop(['time'], axis=1, inplace=True)\n",
    "    df['accuracy'] = np.log10(df['accuracy']).astype(float)\n",
    "    return df\n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "train = prepare_data(train)\n",
    "test = prepare_data(test)\n",
    "\n",
    "fw = [0.61,0.32435, 0.56525, 0.2670, 22, 52, 0.51885]\n",
    "\n",
    "train = apply_weights(train, fw)\n",
    "test = apply_weights(test, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xfrange(start, end, step):\n",
    "    gens = [];\n",
    "    end = round(end, 4)\n",
    "    start = round(start, 4)\n",
    "    while(start < end):\n",
    "        gens.append(start)\n",
    "        start = round(start + step, 4)\n",
    "            \n",
    "    return gens\n",
    "        \n",
    "def gen_ranges(start, end, step):\n",
    "    return zip(xfrange(start, end, step), xfrange(start + step, end + step, step));\n",
    "\n",
    "size = 10.0;\n",
    "\n",
    "x_step = 0.5\n",
    "y_step = 0.25\n",
    "\n",
    "x_ranges = gen_ranges(0, size, x_step);\n",
    "y_ranges = gen_ranges(0, size, y_step);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1219540, 10)\n",
      "(1045320, 10)\n",
      "(174220, 10)\n"
     ]
    }
   ],
   "source": [
    "size_cv = 2.0;\n",
    "\n",
    "x_cv_start = 6;\n",
    "x_cv_end = x_cv_start + size_cv\n",
    "y_cv_start = 6;\n",
    "y_cv_end = y_cv_start + size_cv;\n",
    "\n",
    "cv = train[(train['x'] >= x_cv_start) & \n",
    "           (train['x'] <= x_cv_end) &\n",
    "           (train['y'] >= y_cv_start) &\n",
    "           (train['y'] <= y_cv_end)]\n",
    "\n",
    "cv = cv.sort_values(by='time', axis=0, ascending=True)\n",
    "train_cv = cv[cv.shape[0]//7:]\n",
    "test_cv = cv[:cv.shape[0]//7]\n",
    "\n",
    "print cv.shape\n",
    "print train_cv.shape\n",
    "print test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6.0, 6.5), (6.5, 7.0), (7.0, 7.5), (7.5, 8.0)]\n",
      "[(6.0, 6.25), (6.25, 6.5), (6.5, 6.75), (6.75, 7.0), (7.0, 7.25), (7.25, 7.5), (7.5, 7.75), (7.75, 8.0)]\n"
     ]
    }
   ],
   "source": [
    "x_step = 1.0\n",
    "y_step = 0.25\n",
    "\n",
    "x_ranges_cv = gen_ranges(x_cv_start, x_cv_end, x_step);\n",
    "y_ranges_cv = gen_ranges(y_cv_start, y_cv_end, y_step);\n",
    "print x_ranges_cv\n",
    "print y_ranges_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_predict_proba_2clf(X, y, test):\n",
    "    \n",
    "    #return test;\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    clf1 = KNeighborsClassifier(n_neighbors=20, \n",
    "                                weights=lambda x: x ** -2, metric='manhattan',n_jobs=-1)\n",
    "    \n",
    "    #clf1 = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1,\n",
    "    #                              min_samples_split=4, random_state=0, criterion='entropy')\n",
    "    \n",
    "    clf2 = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1,\n",
    "                                  min_samples_split=4, random_state=0, criterion='gini')\n",
    " \n",
    "    preds_level1 = pd.DataFrame()\n",
    "    \n",
    "    row_ids = test.index.values\n",
    "    \n",
    "    clf1.fit(X, y)\n",
    "    y_pred_1 = clf1.predict_proba(test)\n",
    "    y_pred_1 = dict(zip(le.inverse_transform(clf1.classes_), zip(*y_pred_1)))\n",
    "    y_pred_1 = pd.DataFrame.from_dict(y_pred_1)\n",
    "    \n",
    "    y_pred_1['row_id'] = row_ids\n",
    "    y_pred_1 = y_pred_1.set_index('row_id')\n",
    "    y_pred_1.index.name = 'row_id';\n",
    "    \n",
    "    clf2.fit(X, y)\n",
    "    y_pred_2 = clf2.predict_proba(test)\n",
    "    y_pred_2 = dict(zip(le.inverse_transform(clf2.classes_), zip(*y_pred_2)))\n",
    "    y_pred_2 = pd.DataFrame.from_dict(y_pred_2)\n",
    "    \n",
    "    y_pred_2['row_id'] = row_ids\n",
    "    y_pred_2 = y_pred_2.set_index('row_id')\n",
    "    y_pred_2.index.name = 'row_id';\n",
    "    all_columns = y_pred_1.columns\n",
    "    y_pred_1.rename(columns = lambda x: str(x)+'_1', inplace=True)\n",
    "    y_pred_2.rename(columns = lambda x: str(x)+'_2', inplace=True)\n",
    "    \n",
    "    preds_level1 = pd.concat([y_pred_1, y_pred_2], axis=1)\n",
    "    #print preds_level1.shape\n",
    "    return preds_level1\n",
    "\n",
    "def process_cell(train_cell, test_cell):\n",
    "    \n",
    "    X = train_cell.drop(['place_id'], axis=1)\n",
    "    y = train_cell['place_id']\n",
    "    row_ids =  test_cell.index.values\n",
    "\n",
    "    #skf = StratifiedKFold(np.zeros(shape=y.shape), n_folds=10)\n",
    "    preds_train_level1 = pd.DataFrame()\n",
    "    \n",
    "    X_1 = X[X.shape[0]//9:]\n",
    "    y_1 = y[y.shape[0]//9:]\n",
    "    \n",
    "    X_2 = X[:X.shape[0]//9]\n",
    "    y_2 = y[:y.shape[0]//9]\n",
    "    \n",
    "    preds_train_level1 = fit_predict_proba_2clf(X_1, y_1, X_2)\n",
    "    \n",
    "    #for train_index, test_index in skf:\n",
    "    #    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    #    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #    #print len(y_train.unique())\n",
    "    #    preds_augumented = fit_predict_proba_2clf(X_train, y_train, X_test)\n",
    "    #    preds_train_level1 = pd.concat([preds_train_level1, preds_augumented], axis=0).fillna(value=0)\n",
    "    \n",
    "    print preds_train_level1.shape\n",
    "    print len(y.unique())\n",
    "    \n",
    "    summed = pd.DataFrame()\n",
    "    summed['row_id'] = row_ids\n",
    "    summed = summed.set_index('row_id')\n",
    "    \n",
    "    preds_test_level1 = fit_predict_proba_2clf(X, y, test_cell).fillna(value=0)\n",
    "\n",
    "    for pair in y.unique():\n",
    "        col_1 = str(pair)+'_1'\n",
    "        col_2 = str(pair)+'_2'\n",
    "        #meta_clf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1,\n",
    "        #                          min_samples_split=4, random_state=0)\n",
    "        meta_clf = LogisticRegression();\n",
    "        y_small = y_2.apply(lambda x: 1 if x == pair else 0)\n",
    "        preds_train_level1_small = preds_train_level1.loc[:,[col_1, col_2]]\n",
    "        meta_clf.fit(preds_train_level1_small, y_small)\n",
    "\n",
    "        preds_test_level1_small = preds_test_level1.loc[:,[col_1, col_2]]\n",
    "        summed[pair] = meta_clf.predict_proba(preds_test_level1_small)[:,1]\n",
    "        #summed[pair] = preds_test_level1[col_1]*2 + preds_test_level1[col_2]\n",
    "    \n",
    "    print summed.shape\n",
    "    \n",
    "    return summed\n",
    "    \n",
    "    \n",
    "def process_column(x_min, x_max, y_ranges, x_end, y_end, train, test, preds_total):\n",
    "    start_time_column = time.time()\n",
    "    preds_total[x_min] = pd.DataFrame();\n",
    "    preds_total_column = pd.DataFrame();\n",
    "    for y_min, y_max in  y_ranges: \n",
    "        start_time_cell = time.time()\n",
    "        \n",
    "        if x_max == x_end:\n",
    "            x_max = x_max + 0.001\n",
    "        \n",
    "        if y_max == y_end:\n",
    "            y_max = y_max + 0.001\n",
    "\n",
    "        train_cell = train[(train['x'] >= x_min - 0.03) &\n",
    "                           (train['x'] < x_max + 0.03)&\n",
    "                           (train['y'] >= y_min - 0.015) &\n",
    "                           (train['y'] < y_max + 0.015)]\n",
    "\n",
    "        train_cell = train_cell.drop(['time'], axis=1)\n",
    "        train_cell = train_cell.set_index('row_id')\n",
    "        train_cell = train_cell.groupby(\"place_id\").filter(lambda x: len(x) >= 8)\n",
    "\n",
    "        test_cell = test[(test['y'] >= y_min) &\n",
    "                         (test['y'] < y_max)&\n",
    "                         (test['x'] >= x_min) &\n",
    "                         (test['x'] < x_max)]\n",
    "\n",
    "        test_cell = test_cell.drop(['time'], axis=1)\n",
    "        test_cell = test_cell.set_index('row_id')\n",
    "        \n",
    "        train_cell.loc[:,'x'] *= 490.0\n",
    "        train_cell.loc[:,'y'] *= 980.0\n",
    "        test_cell.loc[:,'x'] *= 490.0\n",
    "        test_cell.loc[:,'y'] *= 980.0\n",
    "        \n",
    "        chunk = process_cell(train_cell, test_cell)\n",
    "\n",
    "        chunk['l1'], chunk['l2'], chunk['l3'] = \\\n",
    "            zip(*chunk.apply(lambda x: chunk.columns[x.argsort()[::-1][:3]].tolist(), axis=1));\n",
    "\n",
    "        chunk = chunk[['l1','l2','l3']];\n",
    "        preds_total_column = pd.concat([preds_total_column, chunk], axis=0);\n",
    "            \n",
    "    preds_total[x_min] = preds_total_column  \n",
    "    print(\"Elapsed time column: %s minutes\" % ((time.time() - start_time_column)/60))\n",
    "\n",
    "def model(x_ranges, y_ranges, x_end, y_end, train, test):   \n",
    "    start_time = time.time()\n",
    "    jobs = []\n",
    "    mgr = Manager()\n",
    "    preds_total = mgr.dict();\n",
    "    for x_min, x_max in  x_ranges:\n",
    "    \n",
    "        p = multiprocessing.Process(target=process_column, args=(x_min, x_max, y_ranges, \\\n",
    "                                                                 x_end, y_end, train, test, preds_total))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        if len(jobs) == 1:\n",
    "            for proc in jobs:\n",
    "                proc.join();\n",
    "            jobs = [];\n",
    "        \n",
    "    print(\"Elapsed time overall: %s minutes\" % ((time.time() - start_time)/60))\n",
    "    \n",
    "    preds_total = pd.concat(preds_total.values(), axis=0);\n",
    "    print preds_total.shape\n",
    "    \n",
    "    return preds_total.sort_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29071, 650)\n",
      "325\n",
      "(32498, 724)\n",
      "362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-17-1b0af0ba0fa4>\", line 125, in process_column\n",
      "    chunk = process_cell(train_cell, test_cell)\n",
      "  File \"<ipython-input-17-1b0af0ba0fa4>\", line 59, in process_cell\n",
      "    preds_augumented = fit_predict_proba_2clf(X_train, y_train, X_test)\n",
      "  File \"<ipython-input-17-1b0af0ba0fa4>\", line 30, in fit_predict_proba_2clf\n",
      "    clf2.fit(X, y)\n",
      "  File \"/Library/Python/2.7/site-packages/scikit_learn-0.17-py2.7-macosx-10.10-intel.egg/sklearn/ensemble/forest.py\", line 290, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"/Library/Python/2.7/site-packages/scikit_learn-0.17-py2.7-macosx-10.10-intel.egg/sklearn/externals/joblib/parallel.py\", line 812, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Library/Python/2.7/site-packages/scikit_learn-0.17-py2.7-macosx-10.10-intel.egg/sklearn/externals/joblib/parallel.py\", line 731, in retrieve\n",
      "    self._output.extend(job.get())\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 556, in wait\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 561, in get\n",
      "    self.wait(timeout)\n",
      "    self._cond.wait(timeout)\n",
      "    waiter.acquire()\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 340, in wait\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-969f9b800f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ranges_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ranges_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cv_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1b0af0ba0fa4>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(x_ranges, y_ranges, x_end, y_end, train, test)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0m_current_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mdeadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = model(x_ranges_cv, y_ranges_cv, x_cv_end, y_cv_end, train_cv, test_cv.drop(['place_id'], axis=1));\n",
    "actual = test_cv[['place_id']].sort_index();\n",
    "print actual.shape\n",
    "print mapk(np.array([actual.values.flatten()]).T, predictions.values, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10247, 3)\n",
      "                  l1          l2          l3\n",
      "row_id                                      \n",
      "21129770  4510055374  9249337909  2636897860\n",
      "21339598  4510055374  9249337909  2636897860\n",
      "21476034  4510055374  5831595982  9249337909\n",
      "21582050  4510055374  5831595982  9249337909\n",
      "22346415  4510055374  5831595982  9249337909\n",
      "22674182  5831595982  4510055374  9249337909\n",
      "22934869  4510055374  9249337909  2636897860\n",
      "22973115  5831595982  4510055374  9249337909\n",
      "23530832  4510055374  9249337909  2636897860\n",
      "23634771  4510055374  9249337909  2636897860\n",
      "23871483  5831595982  9249337909  4510055374\n",
      "24346842  5831595982  9249337909  4510055374\n",
      "24805418  4510055374  9249337909  2636897860\n",
      "24816592  5831595982  9249337909  4510055374\n",
      "24894472  5831595982  9249337909  4510055374\n",
      "24940423  4510055374  9249337909  2636897860\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape\n",
    "#print predictions[predictions.l1 != 5014521982]\n",
    "print predictions.loc[predictions.index.isin([21129770,21339598,21476034,\n",
    "                                           21582050,22346415,22674182,\n",
    "                                           22934869,22973115,23530832,\n",
    "                                           23634771,23871483,24346842,\n",
    "                                           24805418,24816592,24894472,\n",
    "                                           24940423, 7654])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time column: 15.6289599657 minutes\n",
      "Elapsed time column: 17.8379606684 minutes\n",
      "Elapsed time column: 18.6429466009 minutes\n",
      "Elapsed time column: 19.3398334702 minutes\n",
      "Elapsed time column: 20.1132657687 minutes\n",
      "Elapsed time column: 21.3575217684 minutes\n",
      "Elapsed time column: 21.5296566327 minutes\n",
      "Elapsed time column: 21.5479592999 minutes\n",
      "Elapsed time column: 21.5744784673 minutes\n",
      "Elapsed time column: 22.1243719856 minutes\n",
      "Elapsed time column: 19.1988959511 minutes\n",
      "Elapsed time column: 19.4457983812 minutes\n",
      "Elapsed time column: 19.6714697838 minutes\n",
      "Elapsed time column: 20.130786399 minutes\n",
      "Elapsed time column: 20.3939861337 minutes\n",
      "Elapsed time column: 16.0720068494 minutes\n",
      "Elapsed time column: 17.3344372988 minutes\n",
      "Elapsed time column: 18.6908761342 minutes\n",
      "Elapsed time column: 18.7616165837 minutes\n",
      "Elapsed time column: 19.5174747507 minutes\n",
      "Elapsed time overall: 82.1650434494 minutes\n",
      "(8607230, 3)\n"
     ]
    }
   ],
   "source": [
    "preds_total = modelq(x_ranges, y_ranges, size, size, train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
