{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "(8607230, 10)\n",
      "[[-1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8]\n",
      " [-1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8]\n",
      " [-1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8 -1.8]]\n",
      "writing submission file...\n",
      "End of program\n"
     ]
    }
   ],
   "source": [
    "'''Contains additions from several excellent scripts and ideas posted on the forum\n",
    "\n",
    "The script does the following:\n",
    "- calculates time features for test and train\n",
    "- calculates knn using a grid. Top 10 probabilities are calculated\n",
    "- calculates probability lookup tables for main features like hour etc\n",
    "- multiplies knn probabilities with probabilities from lookup tables to give total probability\n",
    "- selects top 3 placeids based on total probability and generates submission file\n",
    "- cross-validation is included (for all grid cells as well as one grid cell)\n",
    "- takes 30 min  to run and produces a score of 0.5865 lb\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "\n",
    "## Parameters\n",
    "cross_validation = 0 # 1 = cross validation, 0 = test data submission\n",
    "onecell=0 # 0 = all grid cells, 1 = one grid cell specified by grid_onecell\n",
    "grid_onecell = 200\n",
    "\n",
    "\n",
    "n_cell_x=20 \n",
    "n_cell_y=40\n",
    "th = 8 ## threshold events below which placeids are excluded from train data\n",
    "\n",
    "\n",
    "########### set weights for knn\n",
    "\n",
    "## I have used a weight matrix below. Weights for each grid can be customized (not included in this script)\n",
    "# 0-x,1-y,2-hour,3-weekday,4-month, 5-year, 6 - accuracy, 7-nearestneighbors \n",
    "weights = np.tile(np.array([490.0, 980.0, 4.0, 3.1, 2.1, 10.0, 10.0, 36])[:,None],n_cell_x*n_cell_y).T #feature weights\n",
    "\n",
    "def calcgridwisemap3(group): \n",
    "    score = ([1/1.0, 1/2.0, 1/3.0]*(np.asarray(group[['ytest']]) == np.asarray(group[['id1','id2','id3']])) ).sum()/group.shape[0]\n",
    "    return score\n",
    "    \n",
    "def makeprobtable(train, feature, threshold):\n",
    "    table = train.groupby('place_id')[feature].value_counts()\n",
    "    table = table/train.groupby('place_id')[feature].count()\n",
    "    table = table.reset_index(level=0, drop=True)  #drop placeid index\n",
    "    table[0]=0 # all missing indices have zero probability\n",
    "    table[table < threshold]= threshold  #threshold small probabilities including zeros to threshold value\n",
    "    return table\n",
    "\n",
    "def getprob(ind, table, nn):\n",
    "    split = len(ind)*nn//3 # split array operations for memory management\n",
    "    temp = ind.reshape(-1)\n",
    "    \n",
    "    temp1=np.invert(np.in1d(temp[:split], table.index.values))\n",
    "    temp2=np.invert(np.in1d(temp[split:split*2], table.index.values))\n",
    "    temp3=np.invert(np.in1d(temp[split*2:], table.index.values))\n",
    "    \n",
    "    temp[np.concatenate((temp1,temp2,temp3))] = 0 # find indices that are not in lookup and set to zero\n",
    "    \n",
    "    temp1=table[temp[:split]]\n",
    "    temp2=table[temp[split:split*2]]\n",
    "    temp3=table[temp[split*2:]]\n",
    "    \n",
    "    prob = np.concatenate((temp1,temp2,temp3))\n",
    "    prob = prob.reshape(-1,nn)\n",
    "    return prob\n",
    "\n",
    "def extendgrid(extension_x, extension_y, size_x, size_y, n_cell_x, n_cell_y):\n",
    "    xmin =np.linspace(0,10-size_x,n_cell_x)    \n",
    "    xmax =np.linspace(0+size_x,10,n_cell_x)    \n",
    "    ymin =np.linspace(0,10-size_y,n_cell_y)    \n",
    "    ymax =np.linspace(0+size_y,10,n_cell_y)    \n",
    "    \n",
    "    grid1 = np.tile(xmin,n_cell_y)\n",
    "    grid2 = np.tile(xmax,n_cell_y)\n",
    "    grid3 = np.repeat(ymin,n_cell_x)\n",
    "    grid4 = np.repeat(ymax,n_cell_x)\n",
    "    grid1 = grid1 - extension_x\n",
    "    grid2 = grid2 + extension_x\n",
    "    grid3 = grid3 - extension_y\n",
    "    grid4 = grid4 + extension_y\n",
    "    \n",
    "    grid = np.vstack((grid1,grid2,grid3,grid4)).T\n",
    "    return grid\n",
    "\n",
    "\n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2\n",
    "\n",
    "\n",
    "    \n",
    "################## read data #####################\n",
    "\n",
    "train = pd.read_csv('./input/train.csv',dtype={'place_id': np.int64}, index_col = 0) \n",
    "\n",
    "\n",
    "train['hour'] = ( (train['time']+120)/60)%24+1 \n",
    "train['weekday'] = (train['time']/1440)%7+1 \n",
    "train['month'] = ( train['time'] /43800)%12+1 \n",
    "train['year'] = (train['time']/525600)+1 \n",
    "train['four_hour'] = (train['time']/240)%6+1\n",
    "train['acc'] = np.log10(train['accuracy'])\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "add_data = train[train.hour<2.5]# add data for periodic time that hit the boundary\n",
    "add_data.hour = add_data.hour+24\n",
    "add_data2 = train[train.hour>22.5]\n",
    "add_data2.hour = add_data2.hour-24\n",
    "train = train.append(add_data)\n",
    "train = train.append(add_data2)\n",
    "del add_data,add_data2\n",
    "\n",
    "\n",
    "if cross_validation == 1:\n",
    "    print('Loading cross validation data ...')\n",
    "    \n",
    "    test = train.query('month >=5.0 and year >=2.0')  \n",
    "    train = train.query('~(month >=5.0 and year >=2.0)')\n",
    "    ytrain = train['place_id']\n",
    "    test = test.query('place_id in @ytrain')\n",
    "    ytest = test['place_id']\n",
    "    del test['place_id']\n",
    "    test.reset_index(inplace=True) \n",
    "    test['row_id'] = test.index.values                     \n",
    "    test.set_index('row_id',inplace=True)\n",
    "    \n",
    "    \n",
    "else:    \n",
    "    print('Loading data ...')\n",
    "    test = pd.read_csv('./input/test.csv', index_col = 0)\n",
    "  \n",
    "    test['hour'] = ((test['time']+120)/60)%24+1 \n",
    "    test['weekday'] = (test['time']/1440)%7+1 \n",
    "    test['month'] = (test['time']/43800)%12+1 \n",
    "    test['year'] = (test['time']/525600)+1 \n",
    "    test['four_hour'] = (test['time']/240)%6+1\n",
    "    test['acc'] = np.log10(test['accuracy']) \n",
    "    \n",
    "################## process data #####################\n",
    "\n",
    "#Make grid\n",
    "size_x = 10. / n_cell_x\n",
    "size_y = 10. / n_cell_y\n",
    "    \n",
    "eps = 0.00001  \n",
    "xs = np.where(train.x.values < eps, 0, train.x.values - eps)\n",
    "ys = np.where(train.y.values < eps, 0, train.y.values - eps)\n",
    "pos_x = (xs / size_x).astype(np.int)\n",
    "pos_y = (ys / size_y).astype(np.int)\n",
    "train['grid_cell'] = pos_y * n_cell_x + pos_x\n",
    "\n",
    "xs = np.where(test.x.values < eps, 0, test.x.values - eps)\n",
    "ys = np.where(test.y.values < eps, 0, test.y.values - eps)\n",
    "pos_x = (xs / size_x).astype(np.int)\n",
    "pos_y = (ys / size_y).astype(np.int)\n",
    "test['grid_cell'] = pos_y * n_cell_x + pos_x\n",
    "\n",
    "\n",
    "### extend grid for train data to avoid edge effects\n",
    "extension_x = 0.03\n",
    "extension_y = 0.015\n",
    "    \n",
    "grid = extendgrid(extension_x, extension_y, size_x, size_y, n_cell_x, n_cell_y)\n",
    "\n",
    "\n",
    "######## run knn on all grids ##############\n",
    "\n",
    "indices = np.zeros((test.shape[0], 10), dtype=np.int64)\n",
    "knn_prob = np.zeros((test.shape[0], 10), dtype=np.float64)\n",
    "\n",
    "tr = train[['x','y']]\n",
    "\n",
    "t=time.time()\n",
    "\n",
    "\n",
    "\n",
    "if onecell==0:\n",
    "    repeats = range(n_cell_x*n_cell_y)\n",
    "else:\n",
    "    repeats = [grid_onecell]\n",
    "\n",
    "\n",
    "\n",
    "for g_id in repeats:\n",
    "    if g_id % 100 == 0:\n",
    "        print('iter: %s' %(g_id))\n",
    "        print (time.time()-t)/60\n",
    "    \n",
    "    #Applying classifier to one grid cell\n",
    "    xmin, xmax, ymin, ymax =grid[g_id]   \n",
    "    grid_train = train[(tr.x > xmin) & (tr.x < xmax) & (tr.y > ymin) & (tr.y < ymax)]    \n",
    "\n",
    "    place_counts = grid_train.place_id.value_counts()\n",
    "    mask = (place_counts[grid_train.place_id.values] >= th).values\n",
    "    grid_train = grid_train.loc[mask]\n",
    "\n",
    "    grid_test = test.loc[test.grid_cell == g_id]\n",
    "    row_ids = grid_test.index\n",
    "       \n",
    "    #Preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(grid_train.place_id.values)\n",
    "    X = grid_train[['x', 'y', 'hour', 'weekday', 'month', 'year', 'acc']].values * weights[g_id][:7]\n",
    "    X_test = grid_test[['x', 'y', 'hour', 'weekday', 'month', 'year', 'acc']].values * weights[g_id][:7]\n",
    "    \n",
    "    ###Applying the knn classifier\n",
    "    #nearest = (weights[g_id][7]).copy().astype(int)\n",
    "    nearest = np.floor(np.sqrt(y.size)/5.1282).astype(int)\n",
    "    clf = KNeighborsClassifier(n_neighbors=nearest, weights=calculate_distance,\n",
    "                               metric='cityblock')\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    indices[row_ids] = le.inverse_transform(  np.argsort(y_pred, axis=1)[:,::-1][:,:10]  )  \n",
    "    knn_prob[row_ids] = np.sort(y_pred, axis=1)[:,::-1][:,:10]\n",
    "\n",
    "print ('knn calculations complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### create indices for probability lookup tables. For example:\n",
    "### for placeid = 999999999 and weekday = 5, then the index is wkday_ind = 99999999905\n",
    "train['wkday_ind'] = 10*train['place_id']+np.floor(train['weekday']).astype(np.int64)   \n",
    "train['hr_ind'] = 100*train['place_id']+np.floor(train['hour']).astype(np.int64)\n",
    "train['four_hour_ind'] = 100*train['place_id']+np.floor(train['four_hour']).astype(np.int64)\n",
    "\n",
    "\n",
    "weekday = makeprobtable(train, 'wkday_ind', 0.001)\n",
    "hour = makeprobtable(train, 'hr_ind', 0.001)\n",
    "four_hour = makeprobtable(train, 'four_hour_ind', 0.001)\n",
    "\n",
    "   \n",
    "nn=10\n",
    "\n",
    "wkday_indices=10*indices+np.tile(np.floor(test.weekday[:,None]).astype(np.int64),nn )\n",
    "hr_indices=100*indices+np.tile(np.floor(test.hour[:,None]).astype(np.int64),nn )\n",
    "four_hour_indices=100*indices+np.tile(np.floor(test.four_hour[:,None]).astype(np.int64),nn )\n",
    "\n",
    "weekday_prob = getprob(wkday_indices, weekday, nn)\n",
    "hour_prob = getprob(hr_indices, hour, nn)\n",
    "four_hour_prob = getprob(four_hour_indices, four_hour, nn)\n",
    "\n",
    "\n",
    "total_prob = np.log10(four_hour_prob)*0.1 \\\n",
    "                + np.log10(hour_prob)*0.1 \\\n",
    "                + np.log10(weekday_prob)*0.4\n",
    "                #+ np.log10(knn_prob)*1 \\\n",
    "\n",
    "\n",
    "total_prob_sorted = np.sort(total_prob)[:,::-1] \n",
    "max3index = np.argsort(-total_prob)\n",
    "a = np.indices(max3index.shape)[0]\n",
    "max3placeids = indices[a,max3index]\n",
    "\n",
    "   \n",
    "if cross_validation==1: \n",
    "    ## calculation assumes unique values  \n",
    "    print ('indices:',([1/1.0, 1/2.0, 1/3.0]*(ytest[:,None] == indices[:,0:3]) ).sum()/indices[np.nonzero(indices[:,0])].shape[0])\n",
    "    print ('map3', ([1/1.0, 1/2.0, 1/3.0]*(ytest[:,None] == max3placeids[:,0:3]) ).sum()/max3placeids[np.nonzero(max3placeids[:,0])].shape[0])\n",
    " \n",
    "    ## calculate map3 for each grid \n",
    "    max3placeids1 = pd.DataFrame({'row_id':test.index.values, 'grid_cell': test['grid_cell'], 'ytest': ytest.values, 'id1':max3placeids[:,0],'id2':max3placeids[:,1],'id3':max3placeids[:,2]} )                  \n",
    "    gridwisemap3 = max3placeids1.groupby('grid_cell').apply(calcgridwisemap3)\n",
    "else:    \n",
    "    print ('writing submission file...')\n",
    "    max3placeids = pd.DataFrame({'row_id':test.index.values,'id1':max3placeids[:,0],'id2':max3placeids[:,1],'id3':max3placeids[:,2]} )\n",
    "    max3placeids['place_id']=max3placeids.id1.astype(str).str.cat([max3placeids.id2.astype(str),max3placeids.id3.astype(str)], sep = ' ')       \n",
    "    max3placeids[['row_id','place_id']].to_csv('submission.csv', header=True, index=False )\n",
    "    print ('End of program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8607230, 10)\n"
     ]
    }
   ],
   "source": [
    "print total_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
